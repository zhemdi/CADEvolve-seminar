{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b47fb7",
   "metadata": {},
   "source": [
    "# Тестирование дообученной модели \n",
    "\n",
    "Этот ноутбук позволяет:\n",
    "- загрузить  **дообученную** модель ,\n",
    "- прогнать её на STL из  теста,\n",
    "- визуализировать входные рендеры,\n",
    "- получить предсказанный **CAD-код/генератор** как текст.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10aa346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Параметры ---\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_ID = \"./work_dirs/cadevolve_ft/final_model\"\n",
    "\n",
    "\n",
    "# Один STL\n",
    "STL_PATH = Path(\"../tests/client_01....stl\")   \n",
    "\n",
    "# Сколько вариантов сэмплить (если temperature>0)\n",
    "N_SAMPLES = 1\n",
    "\n",
    "OUT_DIR = Path(\"./test_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"OUT_DIR:\", OUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafc4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Импорты ---\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import trimesh\n",
    "\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from visualization_iso import Plotter\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f245e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "# --- Нормализация STL: center -> 0, max_extent -> 200 (=> [-100,100]) ---\n",
    "def normalize_stl_to_bbox(stl_in: Path, stl_out: Path, target_max_extent: float = 200.0):\n",
    "    mesh = trimesh.load_mesh(stl_in, force=\"mesh\")\n",
    "\n",
    "    # иногда load_mesh возвращает Scene\n",
    "    if isinstance(mesh, trimesh.Scene):\n",
    "        mesh = trimesh.util.concatenate([g for g in mesh.geometry.values()])\n",
    "\n",
    "    if mesh.vertices is None or len(mesh.vertices) == 0:\n",
    "        raise ValueError(f\"Empty mesh: {stl_in}\")\n",
    "\n",
    "    bounds = mesh.bounds  # (min, max)\n",
    "    center = (bounds[0] + bounds[1]) / 2.0\n",
    "    extents = (bounds[1] - bounds[0])\n",
    "    max_extent = float(np.max(extents))\n",
    "\n",
    "    if max_extent <= 0:\n",
    "        raise ValueError(f\"Degenerate mesh with max_extent={max_extent}: {stl_in}\")\n",
    "\n",
    "    scale = target_max_extent / max_extent\n",
    "\n",
    "    # translate to origin\n",
    "    mesh.apply_translation(-center)\n",
    "    # scale\n",
    "    mesh.apply_scale(scale)\n",
    "\n",
    "    stl_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    mesh.export(stl_out)\n",
    "    return dict(center=center.tolist(), extents=extents.tolist(), max_extent=max_extent, scale=scale)\n",
    "\n",
    "norm_stl = OUT_DIR / \"normalized.stl\"\n",
    "stats = normalize_stl_to_bbox(STL_PATH, norm_stl, target_max_extent=200.0)\n",
    "print(\"Normalized STL saved to:\", norm_stl)\n",
    "print(\"Norm stats:\", stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a72a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Загрузка processor + model ---\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16 if device == \"cuda\" else torch.float32,\n",
    "    attn_implementation=\"sdpa\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.tie_weights()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Loaded:\", MODEL_ID)\n",
    "\n",
    "plotter = Plotter()\n",
    "\n",
    "def stl_to_image(stl_path: Path):\n",
    "    return plotter.get_img(stl_path, None, apply_augs=False)\n",
    "\n",
    "def build_messages(pil_img):\n",
    "    return [[\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": pil_img}]},\n",
    "    ]]\n",
    "\n",
    "def generate_code_for_image(pil_img, max_new_tokens=700, temperature=0.0):\n",
    "    messages = build_messages(pil_img)\n",
    "    text = processor.apply_chat_template(messages[0], tokenize=False, add_generation_prompt=True)\n",
    "    imgs, vids = process_vision_info(messages)\n",
    "\n",
    "    inputs = processor(text=[text], images=imgs, videos=vids, padding=True, return_tensors=\"pt\")\n",
    "    inputs = {k: (v.to(device) if hasattr(v, \"to\") else v) for k, v in inputs.items()}\n",
    "\n",
    "    gen_kwargs = dict(\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=(temperature > 0),\n",
    "        temperature=temperature if temperature > 0 else None,\n",
    "    )\n",
    "    gen_kwargs = {k: v for k, v in gen_kwargs.items() if v is not None}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(**inputs, **gen_kwargs)\n",
    "\n",
    "    gen = out[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    pred_text = processor.tokenizer.decode(gen, skip_special_tokens=True)\n",
    "    return pred_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c121b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Прогон 1 STL ---\n",
    "img = stl_to_image(norm_stl)\n",
    "display(img)\n",
    "\n",
    "results = []\n",
    "for k in tqdm(range(N_SAMPLES)):\n",
    "    pred = generate_code_for_image(img, max_new_tokens=700, temperature=0.0)\n",
    "    results.append(pred)\n",
    "\n",
    "print(\"Done. Samples:\", len(results))\n",
    "print(\"\\nPRED (first 1200 chars):\\n\")\n",
    "print(results[0][:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a81f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Сохранение ---\n",
    "out_json = OUT_DIR / \"predictions.json\"\n",
    "payload = {\n",
    "    \"stl_in\": str(STL_PATH),\n",
    "    \"stl_normalized\": str(norm_stl),\n",
    "    \"normalization\": stats,\n",
    "    \"preds\": results,\n",
    "}\n",
    "out_json.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "for i, pred in enumerate(results):\n",
    "    (OUT_DIR / f\"pred_{i:03d}.py\").write_text(pred + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\", out_json.resolve())\n",
    "print(\"PY files in:\", OUT_DIR.resolve())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
